{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 10: \n",
    "\n",
    "El vector X es gaussiano de media nula y matriz de covarianza:\n",
    "\n",
    "$$\n",
    "C_x = \\begin{bmatrix}\n",
    "        1 &    0 &  0\\\\\n",
    "        0 &  2.5 & -0.5\\\\\n",
    "        0 & -0.5 &  2.5\n",
    "      \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "1. Obtenga N = 10000 realizaciones del vector X. Estime la matriz de covarianza y compare el resultado con Cx.\n",
    "2. Obtenga la matriz A tal que Z = AX tenga componentes descorrelacionadas. Esta transformación “blanquea” las componentes de X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Aleatorio Gaussiano\n",
    "Decimos que un vector aleatorio $\\underline{X} \\in \\mathbb{R}^n$ tiene distribución gaussiana de media $\\mu_{\\underline{X}}$ y matriz de covarianza $C_{\\underline{X}}$: $\\underline{X} \\sim \\mathcal{N}(\\mu_{\\underline{x}},C_{\\underline{X}})$, si su función de densidad de probabilidad (fdp) conjunta es:\n",
    "\n",
    "$$ \n",
    "f_{\\underline{X}}(\\underline{x}) = \\frac{1}{\\left(2\\pi\\right)^{n/2} |C_{\\underline{X}}|^{1/2}} \\exp\\left(-\\frac{1}{2} \\left(\\underline{x}-\\mu_{\\underline{x}}\\right)^T\\,C_{\\underline{X}}^{-1}\\,\\left(\\underline{x}-\\mu_{\\underline{x}}\\right)\\right)\n",
    "$$\n",
    "\n",
    "Decimos  que $\\underline{X}$ es no degenerado si $\\exists \\, C_{\\underline{X}}^{-1}$.\n",
    "\n",
    "Por otro lado, dado un vector gaussiano $\\underline{X}\\sim \\mathcal{N}(\\mu_{\\underline{X}},C_{\\underline{X}})$, si le aplicamos una transformación: $\\underline{Y} = A \\underline{X} + \\underline{b}$ obtenemos otro vector gaussiano: $\\underline{Y}\\sim \\mathcal{N}(\\mu_{\\underline{Y}},C_{\\underline{Y}})$ cuyo vector de medias y matriz de covarianza se obtienen como:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mu_{\\underline{Y}} &= \\mathbb{E}\\left[\\underline{Y}\\right] = A\\,\\mathbb{E}\\left[\\underline{X}\\right] + \\underline{b}\\\\\n",
    "&= A\\,\\mu_{\\underline{X}} + \\underline{b}\\\\\n",
    "C_{\\underline{Y}} &= \\mathbb{E}\\left[(\\underline{Y}-\\mu_{\\underline{Y}})\\,(\\underline{Y}-\\mu_{\\underline{Y}})^T\\right]\\\\\n",
    "&= \\mathbb{E}\\left[(A \\underline{X}+\\underline{b}-A\\,\\mu_{\\underline{X}}-\\underline{b})\\,(A \\underline{X}+\\underline{b}-A\\,\\mu_{\\underline{X}}-\\underline{b})^T\\right]\\\\\n",
    "&= \\mathbb{E}\\left[(A \\underline{X}-A\\,\\mu_{\\underline{X}})\\,(A \\underline{X}-A\\,\\mu_{\\underline{X}})^T\\right]\\\\\n",
    "&= A\\,\\mathbb{E}\\left[(\\underline{X}-\\,\\mu_{\\underline{X}})\\,(\\underline{X}-\\mu_{\\underline{X}})^T\\right]\\,A^T\\\\\n",
    "&= A\\,C_{\\underline{X}}\\,A^T\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Podemos usar esta última propiedad para:\n",
    "\n",
    "* **Colorear** un vector gaussiano: a partir de un vector cuyas componentes son gaussianas descorrelacionadas: $\\underline{Z}\\sim\\mathcal{N}(\\underline{0},\\Lambda)$ con $\\Lambda$ diagonal, obtener otro vector gaussiano $\\underline{X}\\sim \\mathcal{N}(\\mu_{\\underline{X}},C_{\\underline{X}})$.\n",
    "* **Blanquear** un vector gaussiano:  a partir de un vector gaussiano: $\\underline{Y}\\sim \\mathcal{N}(\\mu_{\\underline{Y}},C_{\\underline{Y}})$ hallar otro vector gaussiano cuyas componentes estén descorrelacionadas $\\mathcal{N}(\\underline{0},\\Lambda)$ donde $\\Lambda$ es una matriz diagonal. Esto último en caso gaussiano corresponde a que las componentes del vector sean independientes.\n",
    "\n",
    "En el Ejercicio 7 vimos la Trasnsformada de Box-Muller que nos permite generar de forma sencilla realizaciones de un vector gaussiano en $\\mathbb{R}^2$: $\\mathcal{N}(\\underline{0}_{2\\times 1},I_{2\\times2})$ a partir de realizaciones de 2 variabes aleatorias uniformes. Coloreando ese vector podemos además generar realizaciones de un vector $\\underline{X}\\sim \\mathcal{N}(\\mu_{\\underline{X}},C_{\\underline{X}})$.\n",
    "\n",
    "En cualquiera de estos dos casos: ¿cómo obtenemos A a partir de una dada $C_{\\underline{X}}$?\n",
    "\n",
    "Usando la propiedad anterior, podemos obtener $A$ factorizando la matriz $C_{\\underline{X}}$ que por ser matriz de covarianza es simétrica y (semi) definida positiva. Vamos a ver 3 métodos para hacerlo.\n",
    "\n",
    "### Método 1\n",
    "\n",
    "Diagonalicemos la matriz de covarianza $C_{\\underline{X}}$:\n",
    "\n",
    "$$\n",
    "C_{\\underline{X}} = P\\,D\\,P^{-1}\n",
    "$$\n",
    "\n",
    "Por propiedades de la matriz de covarianza sabemos que $C_{\\underline{X}}$ es una [matriz simétrica](https://en.wikipedia.org/wiki/Symmetric_matrix) y por lo tanto la matriz de autovectores es ortogonal (unitaria) y cumple: $P^{-1}=P^{T}$. Entonces:\n",
    "\n",
    "$$\n",
    "C_{\\underline{X}} = P\\,D\\,P^{T}\n",
    "$$\n",
    "\n",
    "Por otro lado, $D$ es una matriz diagonal y entonces podemos descomponerla como: $D = D^{1/2}\\,D^{1/2}$. Asimismo, $D^{1/2}$ también es una matriz diagonal y por lo tanto es simétrica. Con todo esto:\n",
    "\n",
    "$$\n",
    "C_{\\underline{X}} = P\\,D^{1/2}\\,\\left(D^{1/2}\\right)^{T}\\,P^{T} = A \\,A^{T} \n",
    "$$\n",
    "\n",
    "con $A=P\\,D^{1/2}$.\n",
    "\n",
    "Podemos ver que $A$ calculada de esta manera no es simétrica.\n",
    "\n",
    "### Método 2\n",
    "\n",
    "Usamos nuevamente la descomposición de autovectores y autovalores, pero esta vez logramos una una $A$ simétrica:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "C_{\\underline{X}} &= P\\,D^{1/2}\\,\\left(D^{1/2}\\right)^{T}\\,P^{T} \\\\\n",
    "&= P\\,D^{1/2}\\, I \\, \\left(D^{1/2}\\right)^{T} \\, P^{T}\\\\\n",
    "&= P\\,D^{1/2}\\, P^{T} \\, P \\, \\left(D^{1/2}\\right)^{T} \\, P^{T}\\\\\n",
    "&= \\left(P\\,D^{1/2}\\, P^{T} \\right) \\, \\left(P\\,D^{1/2}\\, P^{T} \\right)^{T} \\\\\n",
    "&= A\\, A^{T}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "donde aprovechamos el hecho que $P$ es una matriz ortogonal y entonces: $P^{T} = P^{-1}$. Podemos ver que en este caso: $A = \\left(P\\,D^{1/2}\\, P^{T} \\right)$ si es una matriz simétrica.\n",
    "\n",
    "### Método 3\n",
    "Usamos la [Descomposición de Cholesky](https://en.wikipedia.org/wiki/Cholesky_decomposition) de $C_{\\underline{X}}$ para decomponerla en el producto de una matriz y su traspueta: \n",
    "$$\n",
    "C_{\\underline{X}}=A\\,A^T\n",
    "$$\n",
    "\n",
    "Volvamos al Ejercicio 10..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 1 \n",
    "\n",
    "Obtenga N = 10000 realizaciones del vector X. Estime la matriz de covarianza y compare el resultado con Cx.\n",
    "\n",
    "Vamos a asumir que asumir que partimos de N realizaciones de un vector normal y vamos a colorearlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos las librerías que vamos a utilizar\n",
    "import math as m\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos N realizaciones de un vector gaussiano normal: $\\underline{Y} \\sim \\mathcal{N}(\\mu_{\\underline{Y}},C_{\\underline{Y}})$ con $\\mu_{\\underline{Y}}=\\underline{0}_{3\\times1}$ y $C_{\\underline{Y}} = I_{3\\times3}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(1e4)\n",
    "Y = np.random.randn(3,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de las realizaciones de $\\underline{Y}$ generamos las N realizaciones de $\\underline{X}$ pedidas. Primero notemos que en este caso: $\\underline{b} = \\underline{0}$. Luego, hallemos la matriz $A$, tal que:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "C_{\\underline{X}} &= A\\,I\\,A^{T}\\\\\n",
    "&= A\\,A^{T}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cx = np.array([[1,0,0],[0,2.5,-0.5],[0,-0.5,2.5]])\n",
    "# hallemos la descomposición en autovalores y autovectores de Cx\n",
    "L,P = np.linalg.eig(Cx)\n",
    "Pi = P.transpose()\n",
    "D = np.diag(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Método 1: $A=P\\,D^{1/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = \n",
      "[[ 0.          0.          1.        ]\n",
      " [-1.22474487  1.          0.        ]\n",
      " [ 1.22474487  1.          0.        ]]\n",
      "Cx = \n",
      "[[ 1.   0.   0. ]\n",
      " [ 0.   2.5 -0.5]\n",
      " [ 0.  -0.5  2.5]]\n"
     ]
    }
   ],
   "source": [
    "A1 = np.dot(P,np.sqrt(D))\n",
    "print('A = ')\n",
    "print(A1)\n",
    "# podemos verificar que Cx = A1 A1^T\n",
    "print('Cx = ')\n",
    "print(np.dot(A1,A1.transpose()))\n",
    "# aplicamos la transformación: X1 = A1 X + b\n",
    "X1 = np.dot(A1,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Método 2: $A = \\left(P\\,D^{1/2}\\, P^{T} \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = \n",
      "[[ 1.          0.          0.        ]\n",
      " [ 0.          1.57313218 -0.15891862]\n",
      " [ 0.         -0.15891862  1.57313218]]\n",
      "Cx = \n",
      "[[ 1.   0.   0. ]\n",
      " [ 0.   2.5 -0.5]\n",
      " [ 0.  -0.5  2.5]]\n"
     ]
    }
   ],
   "source": [
    "A2 = np.dot(A1,Pi)\n",
    "print('A = ')\n",
    "print(A2)\n",
    "# podemos verificar que Cx = A2 A2^T\n",
    "print('Cx = ')\n",
    "print(np.dot(A2,A2.transpose()))\n",
    "# aplicamos la transformación: X2 = A2 X + b\n",
    "X2 = np.dot(A2,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Método 3: Descomposición de Cholesky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = \n",
      "[[ 1.          0.          0.        ]\n",
      " [ 0.          1.58113883  0.        ]\n",
      " [ 0.         -0.31622777  1.54919334]]\n",
      "Cx = \n",
      "[[ 1.   0.   0. ]\n",
      " [ 0.   2.5 -0.5]\n",
      " [ 0.  -0.5  2.5]]\n"
     ]
    }
   ],
   "source": [
    "A3 = np.linalg.cholesky(Cx)\n",
    "print('A = ')\n",
    "print(A3)\n",
    "# podemos verificar que Cx = A3 A3^T\n",
    "print('Cx = ')\n",
    "print(np.dot(A3,A3.transpose()))\n",
    "# aplicamos la transformación: X3 = A3 X + b\n",
    "X3 = np.dot(A3,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de las realizaciones generadas, podemos verificar la transformación calculando empíricamente $C_{\\underline{X}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cx = \n",
      "[[ 1.  -0.  -0. ]\n",
      " [-0.   2.5 -0.5]\n",
      " [-0.  -0.5  2.5]]\n",
      "mux = \n",
      "[-0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# estimacion de la matriz de covarianza\n",
    "Cx_calc = np.cov(X1)\n",
    "# estimacion de la media\n",
    "mux_calc = np.mean(X1,axis=1)\n",
    "print('Cx = ')\n",
    "print(np.matrix.round(Cx_calc,1))\n",
    "print('mux = ')\n",
    "print(np.matrix.round(mux_calc,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punto 2\n",
    "\n",
    "Obtenga la matriz A tal que Z = AX tenga componentes descorrelacionadas. Esta transformación “blanquea” las componentes de X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto queremos blanquear las componentes del vector $\\underline{X}$, es decir, queremos descorrelacionar las componentes del vector $\\underline{X} = \\left[X_1,X_2,X_3\\right]^T$ obtenido en el punto anterior. La matriz de covarianza:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "C_{\\underline{Z}} &= \\mathbb{E} \\left[ \\underline{Z} \\, \\underline{Z}^T \\right] \\\\\n",
    "&= \\mathbb{E}\\left[\\begin{bmatrix}\n",
    "                        Z_1\\\\\n",
    "                        Z_2\\\\\n",
    "                        Z_3\n",
    "                    \\end{bmatrix}\\,\\left[Z_1,Z_2,Z_3\\right]\\right]\\\\\n",
    "&= \\begin{bmatrix}\n",
    "\\mathbb{E}\\left[Z_1^2\\right] & \\mathbb{E}\\left[Z_1\\,Z_2\\right] & \\mathbb{E}\\left[Z_1\\,Z_3\\right]\\\\\n",
    "\\mathbb{E}\\left[Z_2\\,Z_1\\right] & \\mathbb{E}\\left[Z_2^2\\right] & \\mathbb{E}\\left[Z_2\\,Z_3\\right]\\\\\n",
    "\\mathbb{E}\\left[Z_3\\,Z_1\\right] & \\mathbb{E}\\left[Z_3\\,Z_2\\right] & \\mathbb{E}\\left[Z_3^2\\right]\n",
    "\\end{bmatrix}\\\\\n",
    "&= \\begin{bmatrix}\n",
    "\\sigma^2_{Z_1} & 0 & 0\\\\\n",
    "0 & \\sigma^2_{Z_2} & 0\\\\\n",
    "0 & 0 & \\sigma^2_{Z_3}\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "donde vemos que las correlaciones entre $Z_i$ y $Z_{j}$ con $i \\neq j$, que corresponden con los términos fuera de la diagonal, son cero. Por lo tanto, tenemos: $\\underline{X}\\sim \\mathcal{N}(\\underline{0},C_{\\underline{X}})$ y queremos obtener $\\underline{Z}\\sim \\mathcal{N}(\\underline{0},\\Lambda)$ con $\\Lambda$ una matriz diagonal.\n",
    "\n",
    "Para esto podemos usar alguno de los métodos que vimos más arriba para obtener $A$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\Lambda &= A\\,C_{\\underline{X}}\\,A^{T}\\\\\n",
    "&=A\\,P\\,D\\,P^{T}\\,A\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Si hacemos $A=P^{T}$ (donde $P$ es la matriz de autovectores) entonces $\\Lambda = D$ que es una matriz diagonal (matriz de autovalores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = \n",
      "[[ 0.         -0.70710678  0.70710678]\n",
      " [ 0.          0.70710678  0.70710678]\n",
      " [ 1.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "A4 = Pi\n",
    "print('A = ')\n",
    "print(A4)\n",
    "Z = np.dot(A4,X3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de las realizaciones generadas, podemos verificar la transformación calculando empíricamente $C_{\\underline{Z}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cz = \n",
      "[[ 3. -0.  0.]\n",
      " [-0.  2. -0.]\n",
      " [ 0. -0.  1.]]\n",
      "muz = \n",
      "[-0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "Cz_calc = np.cov(Z)\n",
    "muz_calc = np.mean(Z,axis=1)\n",
    "print(\"Cz = \")\n",
    "print(np.matrix.round(Cz_calc,1))\n",
    "print(\"muz = \")\n",
    "print(np.matrix.round(muz_calc,1))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
